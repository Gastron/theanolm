/l/senarvi/theanolm-recipes/penn-treebank/nnlm.vocab
THEANO_FLAGS=floatX=float32,device=cuda0
Reading vocabulary from /l/senarvi/theanolm-recipes/penn-treebank/nnlm.vocab.
Computing unigram probabilities for out-of-shortlist words.
Number of words in vocabulary: 10001
Number of words in shortlist: 10001
Number of word classes: 10001
2017-07-30 23:00:58,915 train: TRAINING OPTIONS
2017-07-30 23:00:58,916 train: patience: 0
2017-07-30 23:00:58,916 train: sequence_length: 25
2017-07-30 23:00:58,916 train: stopping_criterion: no-improvement
2017-07-30 23:00:58,916 train: batch_size: 24
2017-07-30 23:00:58,916 train: min_epochs: 1
2017-07-30 23:00:58,916 train: max_epochs: 15
2017-07-30 23:00:58,916 train: validation_frequency: 1
2017-07-30 23:00:58,916 train: max_annealing_count: 0
2017-07-30 23:00:58,916 train: OPTIMIZATION OPTIONS
2017-07-30 23:00:58,916 train: momentum: 0.9
2017-07-30 23:00:58,916 train: noise_sharing: None
2017-07-30 23:00:58,916 train: learning_rate: 20.0
2017-07-30 23:00:58,916 train: method: sgd
2017-07-30 23:00:58,916 train: exclude_unk: False
2017-07-30 23:00:58,916 train: num_noise_samples: 25
2017-07-30 23:00:58,916 train: weights: [ 1.]
2017-07-30 23:00:58,916 train: max_gradient_norm: 5.0
2017-07-30 23:00:58,916 train: cost_function: nce
2017-07-30 23:00:58,917 train: sqr_gradient_decay_rate: 0.999
2017-07-30 23:00:58,917 train: gradient_decay_rate: 0.9
2017-07-30 23:00:58,917 train: epsilon: 1e-06
Creating trainer.
Computing the number of mini-batches in training data.
2017-07-30 23:01:00,243 __init__: One epoch of training data contains 2371 mini-batch updates.
2017-07-30 23:01:00,244 __init__: Class unigram log probabilities are in the range [-13.786758, -2.951697].
2017-07-30 23:01:00,245 __init__: Finding sentence start positions in /teamwork/t40511_asr/c/penn-treebank-project/ptb.train.txt.
2017-07-30 23:01:00,264 _reset: Generating a random order of input lines.
Building neural network.
2017-07-30 23:01:00,271 __init__: Creating layers.
2017-07-30 23:01:00,272 __init__: - NetworkInput name=word_input inputs=[] size=10001 depth=1 devices=[]
2017-07-30 23:01:00,272 __init__: - ProjectionLayer name=projection_layer inputs=[word_input] size=100 depth=1 devices=[None]
2017-07-30 23:01:00,350 add:      * layers/projection_layer/W size=1000100 type=float32 device=None
2017-07-30 23:01:00,350 __init__: - LSTMLayer name=hidden_layer inputs=[projection_layer] size=256 depth=1 devices=[None]
2017-07-30 23:01:00,358 add:      * layers/hidden_layer/layer_input/W size=102400 type=float32 device=None
2017-07-30 23:01:00,603 add:      * layers/hidden_layer/step_input/W size=262144 type=float32 device=None
2017-07-30 23:01:00,604 add:      * layers/hidden_layer/layer_input/b size=1024 type=float32 device=None
2017-07-30 23:01:00,604 __init__: - SoftmaxLayer name=output_layer inputs=[hidden_layer] size=10001 depth=1 devices=[None]
2017-07-30 23:01:00,824 add:      * layers/output_layer/input/W size=2560256 type=float32 device=None
2017-07-30 23:01:00,824 add:      * layers/output_layer/input/b size=10001 type=float32 device=None
2017-07-30 23:01:00,824 __init__: Total number of parameters: 3935925
Compiling optimization function.
2017-07-30 23:01:02,266 add:      * layers/hidden_layer/layer_input/W_gradient size=102400 type=float32 device=None
2017-07-30 23:01:02,266 add:      * layers/hidden_layer/layer_input/b_gradient size=1024 type=float32 device=None
2017-07-30 23:01:02,271 add:      * layers/output_layer/input/W_gradient size=2560256 type=float32 device=None
2017-07-30 23:01:02,272 add:      * layers/hidden_layer/step_input/W_gradient size=262144 type=float32 device=None
2017-07-30 23:01:02,272 add:      * layers/output_layer/input/b_gradient size=10001 type=float32 device=None
2017-07-30 23:01:02,274 add:      * layers/projection_layer/W_gradient size=1000100 type=float32 device=None
Building text scorer for cross-validation.
Validation text: /teamwork/t40511_asr/c/penn-treebank-project/ptb.valid.txt
Training neural network.
2017-07-30 23:03:16,203 _log_update: [200] (8.4 %) of epoch 1 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:04:20,037 _log_update: [400] (16.9 %) of epoch 1 -- lr = 2e+01, duration = 31.7 ms
2017-07-30 23:05:23,932 _log_update: [600] (25.3 %) of epoch 1 -- lr = 2e+01, duration = 32.1 ms
2017-07-30 23:06:27,767 _log_update: [800] (33.7 %) of epoch 1 -- lr = 2e+01, duration = 31.7 ms
2017-07-30 23:07:31,628 _log_update: [1000] (42.2 %) of epoch 1 -- lr = 2e+01, duration = 31.7 ms
2017-07-30 23:08:35,517 _log_update: [1200] (50.6 %) of epoch 1 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:09:39,401 _log_update: [1400] (59.0 %) of epoch 1 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:10:43,348 _log_update: [1600] (67.5 %) of epoch 1 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:11:47,216 _log_update: [1800] (75.9 %) of epoch 1 -- lr = 2e+01, duration = 32.0 ms
2017-07-30 23:12:51,114 _log_update: [2000] (84.4 %) of epoch 1 -- lr = 2e+01, duration = 31.7 ms
2017-07-30 23:13:55,017 _log_update: [2200] (92.8 %) of epoch 1 -- lr = 2e+01, duration = 32.0 ms
2017-07-30 23:14:51,572 _validate: [2365] First validation sample, perplexity 324.24.
2017-07-30 23:15:04,095 _validate: [2368] Center of validation, perplexity 341.43.
2017-07-30 23:15:16,613 _validate: [2371] Last validation sample, perplexity 425.27.
2017-07-30 23:15:16,630 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-30 23:15:16,630 _log_validation: [2371] Validation set cost history: [357.5]
2017-07-30 23:15:16,631 _reset: Generating a random order of input lines.
Finished training epoch 1 in 0 hours 13.1 minutes. Best validation perplexity 357.53.
2017-07-30 23:15:25,882 _log_update: [29] (1.2 %) of epoch 2 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:16:29,767 _log_update: [229] (9.7 %) of epoch 2 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:17:33,634 _log_update: [429] (18.1 %) of epoch 2 -- lr = 2e+01, duration = 32.0 ms
2017-07-30 23:18:37,529 _log_update: [629] (26.5 %) of epoch 2 -- lr = 2e+01, duration = 32.1 ms
2017-07-30 23:19:41,435 _log_update: [829] (35.0 %) of epoch 2 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:20:45,330 _log_update: [1029] (43.4 %) of epoch 2 -- lr = 2e+01, duration = 31.7 ms
2017-07-30 23:21:49,239 _log_update: [1229] (51.8 %) of epoch 2 -- lr = 2e+01, duration = 32.2 ms
2017-07-30 23:22:53,098 _log_update: [1429] (60.3 %) of epoch 2 -- lr = 2e+01, duration = 32.0 ms
2017-07-30 23:23:57,002 _log_update: [1629] (68.7 %) of epoch 2 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:25:00,913 _log_update: [1829] (77.1 %) of epoch 2 -- lr = 2e+01, duration = 32.3 ms
2017-07-30 23:26:04,788 _log_update: [2029] (85.6 %) of epoch 2 -- lr = 2e+01, duration = 32.1 ms
2017-07-30 23:27:08,693 _log_update: [2229] (94.0 %) of epoch 2 -- lr = 2e+01, duration = 32.1 ms
2017-07-30 23:27:56,006 _validate: [2365] First validation sample, perplexity 241.84.
2017-07-30 23:28:08,489 _validate: [2368] Center of validation, perplexity 278.56.
2017-07-30 23:28:20,981 _validate: [2371] Last validation sample, perplexity 254.74.
2017-07-30 23:28:20,996 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-30 23:28:20,996 _log_validation: [2371] Validation set cost history: 357.5 [254.7]
2017-07-30 23:28:20,997 _reset: Generating a random order of input lines.
Finished training epoch 2 in 0 hours 13.1 minutes. Best validation perplexity 254.74.
2017-07-30 23:28:39,505 _log_update: [58] (2.4 %) of epoch 3 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:29:43,374 _log_update: [258] (10.9 %) of epoch 3 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:30:47,246 _log_update: [458] (19.3 %) of epoch 3 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:31:51,122 _log_update: [658] (27.8 %) of epoch 3 -- lr = 2e+01, duration = 32.1 ms
2017-07-30 23:32:54,990 _log_update: [858] (36.2 %) of epoch 3 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:33:58,883 _log_update: [1058] (44.6 %) of epoch 3 -- lr = 2e+01, duration = 31.7 ms
2017-07-30 23:35:02,738 _log_update: [1258] (53.1 %) of epoch 3 -- lr = 2e+01, duration = 31.7 ms
2017-07-30 23:36:06,607 _log_update: [1458] (61.5 %) of epoch 3 -- lr = 2e+01, duration = 32.0 ms
2017-07-30 23:37:10,462 _log_update: [1658] (69.9 %) of epoch 3 -- lr = 2e+01, duration = 32.2 ms
2017-07-30 23:38:14,340 _log_update: [1858] (78.4 %) of epoch 3 -- lr = 2e+01, duration = 31.6 ms
2017-07-30 23:39:18,205 _log_update: [2058] (86.8 %) of epoch 3 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:40:22,095 _log_update: [2258] (95.2 %) of epoch 3 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:41:00,154 _validate: [2365] First validation sample, perplexity 259.63.
2017-07-30 23:41:12,639 _validate: [2368] Center of validation, perplexity 227.56.
2017-07-30 23:41:25,143 _validate: [2371] Last validation sample, perplexity 260.60.
2017-07-30 23:41:25,158 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-30 23:41:25,158 _log_validation: [2371] Validation set cost history: 357.5 254.7 [231.3]
2017-07-30 23:41:25,159 _reset: Generating a random order of input lines.
Finished training epoch 3 in 0 hours 13.1 minutes. Best validation perplexity 231.30.
2017-07-30 23:41:52,922 _log_update: [87] (3.7 %) of epoch 4 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:42:56,808 _log_update: [287] (12.1 %) of epoch 4 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:44:00,706 _log_update: [487] (20.5 %) of epoch 4 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:45:04,569 _log_update: [687] (29.0 %) of epoch 4 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:46:08,446 _log_update: [887] (37.4 %) of epoch 4 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:47:12,325 _log_update: [1087] (45.8 %) of epoch 4 -- lr = 2e+01, duration = 31.6 ms
2017-07-30 23:48:16,192 _log_update: [1287] (54.3 %) of epoch 4 -- lr = 2e+01, duration = 31.7 ms
2017-07-30 23:49:20,060 _log_update: [1487] (62.7 %) of epoch 4 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:50:23,935 _log_update: [1687] (71.2 %) of epoch 4 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:51:27,843 _log_update: [1887] (79.6 %) of epoch 4 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:52:31,751 _log_update: [2087] (88.0 %) of epoch 4 -- lr = 2e+01, duration = 32.0 ms
2017-07-30 23:53:35,665 _log_update: [2287] (96.5 %) of epoch 4 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:54:04,445 _validate: [2365] First validation sample, perplexity 255.82.
2017-07-30 23:54:16,925 _validate: [2368] Center of validation, perplexity 207.84.
2017-07-30 23:54:29,424 _validate: [2371] Last validation sample, perplexity 259.19.
2017-07-30 23:54:29,439 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-30 23:54:29,439 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 [207.8]
2017-07-30 23:54:29,440 _reset: Generating a random order of input lines.
Finished training epoch 4 in 0 hours 13.1 minutes. Best validation perplexity 207.84.
2017-07-30 23:55:06,470 _log_update: [116] (4.9 %) of epoch 5 -- lr = 2e+01, duration = 31.9 ms
2017-07-30 23:56:10,327 _log_update: [316] (13.3 %) of epoch 5 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:57:14,203 _log_update: [516] (21.8 %) of epoch 5 -- lr = 2e+01, duration = 31.8 ms
2017-07-30 23:58:18,082 _log_update: [716] (30.2 %) of epoch 5 -- lr = 2e+01, duration = 31.6 ms
2017-07-30 23:59:21,925 _log_update: [916] (38.6 %) of epoch 5 -- lr = 2e+01, duration = 32.0 ms
2017-07-31 00:00:25,800 _log_update: [1116] (47.1 %) of epoch 5 -- lr = 2e+01, duration = 31.6 ms
2017-07-31 00:01:29,641 _log_update: [1316] (55.5 %) of epoch 5 -- lr = 2e+01, duration = 31.9 ms
2017-07-31 00:02:33,558 _log_update: [1516] (63.9 %) of epoch 5 -- lr = 2e+01, duration = 32.0 ms
2017-07-31 00:03:37,421 _log_update: [1716] (72.4 %) of epoch 5 -- lr = 2e+01, duration = 31.8 ms
2017-07-31 00:04:41,292 _log_update: [1916] (80.8 %) of epoch 5 -- lr = 2e+01, duration = 32.1 ms
2017-07-31 00:05:45,156 _log_update: [2116] (89.2 %) of epoch 5 -- lr = 2e+01, duration = 32.0 ms
2017-07-31 00:06:49,039 _log_update: [2316] (97.7 %) of epoch 5 -- lr = 2e+01, duration = 31.7 ms
2017-07-31 00:07:08,560 _validate: [2365] First validation sample, perplexity 188.67.
2017-07-31 00:07:21,079 _validate: [2368] Center of validation, perplexity 192.46.
2017-07-31 00:07:33,602 _validate: [2371] Last validation sample, perplexity 198.09.
2017-07-31 00:07:33,617 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-31 00:07:33,617 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 [193.5]
2017-07-31 00:07:33,618 _reset: Generating a random order of input lines.
Finished training epoch 5 in 0 hours 13.1 minutes. Best validation perplexity 193.53.
2017-07-31 00:08:19,918 _log_update: [145] (6.1 %) of epoch 6 -- lr = 2e+01, duration = 32.0 ms
2017-07-31 00:09:23,826 _log_update: [345] (14.6 %) of epoch 6 -- lr = 2e+01, duration = 32.0 ms
2017-07-31 00:10:27,787 _log_update: [545] (23.0 %) of epoch 6 -- lr = 2e+01, duration = 31.9 ms
2017-07-31 00:11:31,664 _log_update: [745] (31.4 %) of epoch 6 -- lr = 2e+01, duration = 31.8 ms
2017-07-31 00:12:35,555 _log_update: [945] (39.9 %) of epoch 6 -- lr = 2e+01, duration = 32.0 ms
2017-07-31 00:13:39,427 _log_update: [1145] (48.3 %) of epoch 6 -- lr = 2e+01, duration = 32.2 ms
2017-07-31 00:14:43,375 _log_update: [1345] (56.7 %) of epoch 6 -- lr = 2e+01, duration = 31.7 ms
2017-07-31 00:15:47,259 _log_update: [1545] (65.2 %) of epoch 6 -- lr = 2e+01, duration = 31.8 ms
2017-07-31 00:16:51,157 _log_update: [1745] (73.6 %) of epoch 6 -- lr = 2e+01, duration = 31.7 ms
2017-07-31 00:17:55,067 _log_update: [1945] (82.0 %) of epoch 6 -- lr = 2e+01, duration = 31.7 ms
2017-07-31 00:18:58,961 _log_update: [2145] (90.5 %) of epoch 6 -- lr = 2e+01, duration = 31.8 ms
2017-07-31 00:20:02,833 _log_update: [2345] (98.9 %) of epoch 6 -- lr = 2e+01, duration = 31.9 ms
2017-07-31 00:20:13,118 _validate: [2365] First validation sample, perplexity 196.74.
2017-07-31 00:20:25,617 _validate: [2368] Center of validation, perplexity 190.56.
2017-07-31 00:20:38,170 _validate: [2371] Last validation sample, perplexity 203.03.
2017-07-31 00:20:38,170 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 [193.5] 198.2
2017-07-31 00:20:38,172 set_state: layers/projection_layer/W <- array(10001, 100)
2017-07-31 00:20:38,172 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-07-31 00:20:38,173 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-07-31 00:20:38,173 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-07-31 00:20:38,176 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-07-31 00:20:38,177 set_state: layers/output_layer/input/b <- array(10001,)
2017-07-31 00:20:38,178 _reset_state: [2368] (99.87 %) of epoch 5
2017-07-31 00:20:38,178 _log_validation: [2368] Validation set cost history: 357.5 254.7 231.3 207.8 [193.5]
2017-07-31 00:20:38,178 set_state: Restored iterator to line 42026 of 42068.
2017-07-31 00:20:38,179 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-07-31 00:20:38,187 set_state: layers/output_layer/input/W_gradient <- array(256, 10001)
2017-07-31 00:20:38,188 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2017-07-31 00:20:38,189 set_state: layers/output_layer/input/b_gradient <- array(10001,)
2017-07-31 00:20:38,189 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-07-31 00:20:38,189 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
Model performance stopped improving. Decreasing learning rate from 20.0 to 10.0 and resetting state to 100 % of epoch 5.
2017-07-31 00:20:38,190 _reset: Generating a random order of input lines.
Finished training epoch 5 in 0 hours 13.1 minutes. Best validation perplexity 193.53.
2017-07-31 00:21:33,813 _log_update: [174] (7.3 %) of epoch 6 -- lr = 1e+01, duration = 31.8 ms
2017-07-31 00:22:37,708 _log_update: [374] (15.8 %) of epoch 6 -- lr = 1e+01, duration = 31.7 ms
2017-07-31 00:23:41,574 _log_update: [574] (24.2 %) of epoch 6 -- lr = 1e+01, duration = 31.8 ms
2017-07-31 00:24:45,459 _log_update: [774] (32.6 %) of epoch 6 -- lr = 1e+01, duration = 31.9 ms
2017-07-31 00:25:49,358 _log_update: [974] (41.1 %) of epoch 6 -- lr = 1e+01, duration = 31.7 ms
2017-07-31 00:26:53,253 _log_update: [1174] (49.5 %) of epoch 6 -- lr = 1e+01, duration = 31.9 ms
2017-07-31 00:27:57,157 _log_update: [1374] (58.0 %) of epoch 6 -- lr = 1e+01, duration = 31.7 ms
2017-07-31 00:29:01,047 _log_update: [1574] (66.4 %) of epoch 6 -- lr = 1e+01, duration = 31.6 ms
2017-07-31 00:30:04,964 _log_update: [1774] (74.8 %) of epoch 6 -- lr = 1e+01, duration = 31.8 ms
2017-07-31 00:31:08,856 _log_update: [1974] (83.3 %) of epoch 6 -- lr = 1e+01, duration = 31.9 ms
2017-07-31 00:32:12,767 _log_update: [2174] (91.7 %) of epoch 6 -- lr = 1e+01, duration = 31.9 ms
2017-07-31 00:33:17,649 _validate: [2365] First validation sample, perplexity 178.98.
2017-07-31 00:33:30,151 _validate: [2368] Center of validation, perplexity 175.35.
2017-07-31 00:33:42,663 _validate: [2371] Last validation sample, perplexity 178.35.
2017-07-31 00:33:42,678 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-31 00:33:42,678 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 [177.3]
2017-07-31 00:33:42,679 _reset: Generating a random order of input lines.
Finished training epoch 6 in 0 hours 13.1 minutes. Best validation perplexity 177.27.
2017-07-31 00:33:43,622 _log_update: [3] (0.1 %) of epoch 7 -- lr = 1e+01, duration = 31.8 ms
2017-07-31 00:34:47,508 _log_update: [203] (8.6 %) of epoch 7 -- lr = 1e+01, duration = 32.1 ms
2017-07-31 00:35:51,341 _log_update: [403] (17.0 %) of epoch 7 -- lr = 1e+01, duration = 32.4 ms
2017-07-31 00:36:55,264 _log_update: [603] (25.4 %) of epoch 7 -- lr = 1e+01, duration = 31.9 ms
2017-07-31 00:37:59,166 _log_update: [803] (33.9 %) of epoch 7 -- lr = 1e+01, duration = 31.9 ms
2017-07-31 00:39:03,042 _log_update: [1003] (42.3 %) of epoch 7 -- lr = 1e+01, duration = 31.8 ms
2017-07-31 00:40:07,028 _log_update: [1203] (50.7 %) of epoch 7 -- lr = 1e+01, duration = 31.7 ms
2017-07-31 00:41:10,917 _log_update: [1403] (59.2 %) of epoch 7 -- lr = 1e+01, duration = 31.9 ms
2017-07-31 00:42:14,817 _log_update: [1603] (67.6 %) of epoch 7 -- lr = 1e+01, duration = 31.8 ms
2017-07-31 00:43:18,704 _log_update: [1803] (76.0 %) of epoch 7 -- lr = 1e+01, duration = 31.9 ms
2017-07-31 00:44:22,577 _log_update: [2003] (84.5 %) of epoch 7 -- lr = 1e+01, duration = 32.0 ms
2017-07-31 00:45:26,446 _log_update: [2203] (92.9 %) of epoch 7 -- lr = 1e+01, duration = 31.9 ms
2017-07-31 00:46:22,089 _validate: [2365] First validation sample, perplexity 175.57.
2017-07-31 00:46:34,580 _validate: [2368] Center of validation, perplexity 178.00.
2017-07-31 00:46:47,092 _validate: [2371] Last validation sample, perplexity 181.14.
2017-07-31 00:46:47,092 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 [177.3] 178.0
2017-07-31 00:46:47,094 set_state: layers/projection_layer/W <- array(10001, 100)
2017-07-31 00:46:47,095 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-07-31 00:46:47,095 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-07-31 00:46:47,095 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-07-31 00:46:47,098 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-07-31 00:46:47,099 set_state: layers/output_layer/input/b <- array(10001,)
2017-07-31 00:46:47,100 _reset_state: [2368] (99.87 %) of epoch 6
2017-07-31 00:46:47,100 _log_validation: [2368] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 [177.3]
2017-07-31 00:46:47,101 set_state: Restored iterator to line 42028 of 42068.
2017-07-31 00:46:47,101 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-07-31 00:46:47,109 set_state: layers/output_layer/input/W_gradient <- array(256, 10001)
2017-07-31 00:46:47,110 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2017-07-31 00:46:47,111 set_state: layers/output_layer/input/b_gradient <- array(10001,)
2017-07-31 00:46:47,112 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-07-31 00:46:47,112 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
Model performance stopped improving. Decreasing learning rate from 10.0 to 5.0 and resetting state to 100 % of epoch 6.
2017-07-31 00:46:47,113 _reset: Generating a random order of input lines.
Finished training epoch 6 in 0 hours 13.1 minutes. Best validation perplexity 177.27.
2017-07-31 00:46:57,323 _log_update: [32] (1.3 %) of epoch 7 -- lr = 5, duration = 31.9 ms
2017-07-31 00:48:01,231 _log_update: [232] (9.8 %) of epoch 7 -- lr = 5, duration = 31.9 ms
2017-07-31 00:49:05,127 _log_update: [432] (18.2 %) of epoch 7 -- lr = 5, duration = 31.9 ms
2017-07-31 00:50:09,021 _log_update: [632] (26.7 %) of epoch 7 -- lr = 5, duration = 31.9 ms
2017-07-31 00:51:12,901 _log_update: [832] (35.1 %) of epoch 7 -- lr = 5, duration = 31.8 ms
2017-07-31 00:52:16,820 _log_update: [1032] (43.5 %) of epoch 7 -- lr = 5, duration = 32.1 ms
2017-07-31 00:53:20,710 _log_update: [1232] (52.0 %) of epoch 7 -- lr = 5, duration = 31.8 ms
2017-07-31 00:54:24,592 _log_update: [1432] (60.4 %) of epoch 7 -- lr = 5, duration = 31.8 ms
2017-07-31 00:55:28,502 _log_update: [1632] (68.8 %) of epoch 7 -- lr = 5, duration = 32.0 ms
2017-07-31 00:56:32,381 _log_update: [1832] (77.3 %) of epoch 7 -- lr = 5, duration = 31.8 ms
2017-07-31 00:57:36,274 _log_update: [2032] (85.7 %) of epoch 7 -- lr = 5, duration = 31.7 ms
2017-07-31 00:58:40,156 _log_update: [2232] (94.1 %) of epoch 7 -- lr = 5, duration = 32.0 ms
2017-07-31 00:59:26,474 _validate: [2365] First validation sample, perplexity 166.57.
2017-07-31 00:59:38,954 _validate: [2368] Center of validation, perplexity 168.34.
2017-07-31 00:59:51,458 _validate: [2371] Last validation sample, perplexity 172.33.
2017-07-31 00:59:51,473 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-31 00:59:51,473 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 [168.2]
2017-07-31 00:59:51,474 _reset: Generating a random order of input lines.
Finished training epoch 7 in 0 hours 13.1 minutes. Best validation perplexity 168.21.
2017-07-31 01:00:10,951 _log_update: [61] (2.6 %) of epoch 8 -- lr = 5, duration = 31.9 ms
2017-07-31 01:01:14,840 _log_update: [261] (11.0 %) of epoch 8 -- lr = 5, duration = 32.3 ms
2017-07-31 01:02:18,827 _log_update: [461] (19.4 %) of epoch 8 -- lr = 5, duration = 32.0 ms
2017-07-31 01:03:22,724 _log_update: [661] (27.9 %) of epoch 8 -- lr = 5, duration = 31.8 ms
2017-07-31 01:04:26,627 _log_update: [861] (36.3 %) of epoch 8 -- lr = 5, duration = 31.5 ms
2017-07-31 01:05:30,532 _log_update: [1061] (44.7 %) of epoch 8 -- lr = 5, duration = 31.7 ms
2017-07-31 01:06:34,398 _log_update: [1261] (53.2 %) of epoch 8 -- lr = 5, duration = 31.9 ms
2017-07-31 01:07:38,290 _log_update: [1461] (61.6 %) of epoch 8 -- lr = 5, duration = 31.9 ms
2017-07-31 01:08:42,205 _log_update: [1661] (70.1 %) of epoch 8 -- lr = 5, duration = 31.8 ms
2017-07-31 01:09:46,107 _log_update: [1861] (78.5 %) of epoch 8 -- lr = 5, duration = 31.9 ms
2017-07-31 01:10:50,011 _log_update: [2061] (86.9 %) of epoch 8 -- lr = 5, duration = 31.9 ms
2017-07-31 01:11:53,904 _log_update: [2261] (95.4 %) of epoch 8 -- lr = 5, duration = 32.0 ms
2017-07-31 01:12:30,993 _validate: [2365] First validation sample, perplexity 165.37.
2017-07-31 01:12:43,496 _validate: [2368] Center of validation, perplexity 166.42.
2017-07-31 01:12:56,054 _validate: [2371] Last validation sample, perplexity 167.31.
2017-07-31 01:12:56,070 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-31 01:12:56,070 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 [167.3]
2017-07-31 01:12:56,071 _reset: Generating a random order of input lines.
Finished training epoch 8 in 0 hours 13.1 minutes. Best validation perplexity 167.31.
2017-07-31 01:13:24,809 _log_update: [90] (3.8 %) of epoch 9 -- lr = 5, duration = 31.8 ms
2017-07-31 01:14:28,729 _log_update: [290] (12.2 %) of epoch 9 -- lr = 5, duration = 31.6 ms
2017-07-31 01:15:32,620 _log_update: [490] (20.7 %) of epoch 9 -- lr = 5, duration = 31.9 ms
2017-07-31 01:16:36,536 _log_update: [690] (29.1 %) of epoch 9 -- lr = 5, duration = 31.7 ms
2017-07-31 01:17:40,456 _log_update: [890] (37.5 %) of epoch 9 -- lr = 5, duration = 31.9 ms
2017-07-31 01:18:44,329 _log_update: [1090] (46.0 %) of epoch 9 -- lr = 5, duration = 31.7 ms
2017-07-31 01:19:48,195 _log_update: [1290] (54.4 %) of epoch 9 -- lr = 5, duration = 31.9 ms
2017-07-31 01:20:52,076 _log_update: [1490] (62.8 %) of epoch 9 -- lr = 5, duration = 31.7 ms
2017-07-31 01:21:55,959 _log_update: [1690] (71.3 %) of epoch 9 -- lr = 5, duration = 32.0 ms
2017-07-31 01:22:59,829 _log_update: [1890] (79.7 %) of epoch 9 -- lr = 5, duration = 31.8 ms
2017-07-31 01:24:03,726 _log_update: [2090] (88.1 %) of epoch 9 -- lr = 5, duration = 31.8 ms
2017-07-31 01:25:07,584 _log_update: [2290] (96.6 %) of epoch 9 -- lr = 5, duration = 31.7 ms
2017-07-31 01:25:35,390 _validate: [2365] First validation sample, perplexity 169.45.
2017-07-31 01:25:47,865 _validate: [2368] Center of validation, perplexity 169.58.
2017-07-31 01:26:00,371 _validate: [2371] Last validation sample, perplexity 166.03.
2017-07-31 01:26:00,372 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 [167.3] 169.5
2017-07-31 01:26:00,373 set_state: layers/projection_layer/W <- array(10001, 100)
2017-07-31 01:26:00,374 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-07-31 01:26:00,374 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-07-31 01:26:00,374 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-07-31 01:26:00,377 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-07-31 01:26:00,378 set_state: layers/output_layer/input/b <- array(10001,)
2017-07-31 01:26:00,379 _reset_state: [2368] (99.87 %) of epoch 8
2017-07-31 01:26:00,379 _log_validation: [2368] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 [167.3]
2017-07-31 01:26:00,380 set_state: Restored iterator to line 42024 of 42068.
2017-07-31 01:26:00,380 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-07-31 01:26:00,388 set_state: layers/output_layer/input/W_gradient <- array(256, 10001)
2017-07-31 01:26:00,389 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2017-07-31 01:26:00,390 set_state: layers/output_layer/input/b_gradient <- array(10001,)
2017-07-31 01:26:00,390 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-07-31 01:26:00,391 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
Model performance stopped improving. Decreasing learning rate from 5.0 to 2.5 and resetting state to 100 % of epoch 8.
2017-07-31 01:26:00,392 _reset: Generating a random order of input lines.
Finished training epoch 8 in 0 hours 13.1 minutes. Best validation perplexity 167.31.
2017-07-31 01:26:38,378 _log_update: [119] (5.0 %) of epoch 9 -- lr = 2, duration = 32.0 ms
2017-07-31 01:27:42,211 _log_update: [319] (13.5 %) of epoch 9 -- lr = 2, duration = 31.7 ms
2017-07-31 01:28:46,106 _log_update: [519] (21.9 %) of epoch 9 -- lr = 2, duration = 31.8 ms
2017-07-31 01:29:49,949 _log_update: [719] (30.3 %) of epoch 9 -- lr = 2, duration = 31.8 ms
2017-07-31 01:30:53,799 _log_update: [919] (38.8 %) of epoch 9 -- lr = 2, duration = 32.0 ms
2017-07-31 01:31:57,639 _log_update: [1119] (47.2 %) of epoch 9 -- lr = 2, duration = 31.5 ms
2017-07-31 01:33:01,546 _log_update: [1319] (55.6 %) of epoch 9 -- lr = 2, duration = 31.9 ms
2017-07-31 01:34:05,456 _log_update: [1519] (64.1 %) of epoch 9 -- lr = 2, duration = 31.8 ms
2017-07-31 01:35:09,336 _log_update: [1719] (72.5 %) of epoch 9 -- lr = 2, duration = 31.8 ms
2017-07-31 01:36:13,229 _log_update: [1919] (80.9 %) of epoch 9 -- lr = 2, duration = 31.8 ms
2017-07-31 01:37:17,092 _log_update: [2119] (89.4 %) of epoch 9 -- lr = 2, duration = 32.0 ms
2017-07-31 01:38:20,957 _log_update: [2319] (97.8 %) of epoch 9 -- lr = 2, duration = 32.0 ms
2017-07-31 01:38:39,502 _validate: [2365] First validation sample, perplexity 166.47.
2017-07-31 01:38:52,000 _validate: [2368] Center of validation, perplexity 166.00.
2017-07-31 01:39:04,523 _validate: [2371] Last validation sample, perplexity 164.05.
2017-07-31 01:39:04,538 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-31 01:39:04,538 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 [165.5]
2017-07-31 01:39:04,539 _reset: Generating a random order of input lines.
Finished training epoch 9 in 0 hours 13.1 minutes. Best validation perplexity 165.48.
2017-07-31 01:39:51,792 _log_update: [148] (6.2 %) of epoch 10 -- lr = 2, duration = 31.8 ms
2017-07-31 01:40:55,695 _log_update: [348] (14.7 %) of epoch 10 -- lr = 2, duration = 31.8 ms
2017-07-31 01:41:59,570 _log_update: [548] (23.1 %) of epoch 10 -- lr = 2, duration = 31.7 ms
2017-07-31 01:43:03,446 _log_update: [748] (31.5 %) of epoch 10 -- lr = 2, duration = 32.1 ms
2017-07-31 01:44:07,337 _log_update: [948] (40.0 %) of epoch 10 -- lr = 2, duration = 31.9 ms
2017-07-31 01:45:11,221 _log_update: [1148] (48.4 %) of epoch 10 -- lr = 2, duration = 32.0 ms
2017-07-31 01:46:15,081 _log_update: [1348] (56.9 %) of epoch 10 -- lr = 2, duration = 31.9 ms
2017-07-31 01:47:18,948 _log_update: [1548] (65.3 %) of epoch 10 -- lr = 2, duration = 32.1 ms
2017-07-31 01:48:22,814 _log_update: [1748] (73.7 %) of epoch 10 -- lr = 2, duration = 32.1 ms
2017-07-31 01:49:26,661 _log_update: [1948] (82.2 %) of epoch 10 -- lr = 2, duration = 31.8 ms
2017-07-31 01:50:30,549 _log_update: [2148] (90.6 %) of epoch 10 -- lr = 2, duration = 31.9 ms
2017-07-31 01:51:34,418 _log_update: [2348] (99.0 %) of epoch 10 -- lr = 2, duration = 31.9 ms
2017-07-31 01:51:43,704 _validate: [2365] First validation sample, perplexity 164.21.
2017-07-31 01:51:56,178 _validate: [2368] Center of validation, perplexity 164.72.
2017-07-31 01:52:08,692 _validate: [2371] Last validation sample, perplexity 164.70.
2017-07-31 01:52:08,707 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-31 01:52:08,707 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 [164.7]
2017-07-31 01:52:08,708 _reset: Generating a random order of input lines.
Finished training epoch 10 in 0 hours 13.1 minutes. Best validation perplexity 164.70.
2017-07-31 01:53:05,240 _log_update: [177] (7.5 %) of epoch 11 -- lr = 2, duration = 31.9 ms
2017-07-31 01:54:09,149 _log_update: [377] (15.9 %) of epoch 11 -- lr = 2, duration = 31.8 ms
2017-07-31 01:55:13,034 _log_update: [577] (24.3 %) of epoch 11 -- lr = 2, duration = 31.9 ms
2017-07-31 01:56:16,925 _log_update: [777] (32.8 %) of epoch 11 -- lr = 2, duration = 32.0 ms
2017-07-31 01:57:20,831 _log_update: [977] (41.2 %) of epoch 11 -- lr = 2, duration = 31.9 ms
2017-07-31 01:58:24,735 _log_update: [1177] (49.6 %) of epoch 11 -- lr = 2, duration = 31.6 ms
2017-07-31 01:59:28,636 _log_update: [1377] (58.1 %) of epoch 11 -- lr = 2, duration = 31.8 ms
2017-07-31 02:00:32,559 _log_update: [1577] (66.5 %) of epoch 11 -- lr = 2, duration = 32.4 ms
2017-07-31 02:01:36,469 _log_update: [1777] (74.9 %) of epoch 11 -- lr = 2, duration = 31.7 ms
2017-07-31 02:02:40,427 _log_update: [1977] (83.4 %) of epoch 11 -- lr = 2, duration = 31.8 ms
2017-07-31 02:03:44,313 _log_update: [2177] (91.8 %) of epoch 11 -- lr = 2, duration = 32.1 ms
2017-07-31 02:04:48,235 _validate: [2365] First validation sample, perplexity 164.75.
2017-07-31 02:05:00,730 _validate: [2368] Center of validation, perplexity 165.68.
2017-07-31 02:05:13,272 _validate: [2371] Last validation sample, perplexity 163.09.
2017-07-31 02:05:13,273 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 [164.7] 164.8
2017-07-31 02:05:13,274 set_state: layers/projection_layer/W <- array(10001, 100)
2017-07-31 02:05:13,275 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-07-31 02:05:13,275 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-07-31 02:05:13,276 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-07-31 02:05:13,279 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-07-31 02:05:13,279 set_state: layers/output_layer/input/b <- array(10001,)
2017-07-31 02:05:13,280 _reset_state: [2368] (99.87 %) of epoch 10
2017-07-31 02:05:13,281 _log_validation: [2368] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 [164.7]
2017-07-31 02:05:13,281 set_state: Restored iterator to line 42026 of 42068.
2017-07-31 02:05:13,282 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-07-31 02:05:13,289 set_state: layers/output_layer/input/W_gradient <- array(256, 10001)
2017-07-31 02:05:13,291 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2017-07-31 02:05:13,291 set_state: layers/output_layer/input/b_gradient <- array(10001,)
2017-07-31 02:05:13,292 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-07-31 02:05:13,292 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
Model performance stopped improving. Decreasing learning rate from 2.5 to 1.25 and resetting state to 100 % of epoch 10.
2017-07-31 02:05:13,293 _reset: Generating a random order of input lines.
Finished training epoch 10 in 0 hours 13.1 minutes. Best validation perplexity 164.70.
2017-07-31 02:05:15,201 _log_update: [6] (0.3 %) of epoch 11 -- lr = 1, duration = 31.8 ms
2017-07-31 02:06:19,075 _log_update: [206] (8.7 %) of epoch 11 -- lr = 1, duration = 31.6 ms
2017-07-31 02:07:22,964 _log_update: [406] (17.1 %) of epoch 11 -- lr = 1, duration = 31.6 ms
2017-07-31 02:08:26,901 _log_update: [606] (25.6 %) of epoch 11 -- lr = 1, duration = 31.9 ms
2017-07-31 02:09:30,809 _log_update: [806] (34.0 %) of epoch 11 -- lr = 1, duration = 31.8 ms
2017-07-31 02:10:34,734 _log_update: [1006] (42.4 %) of epoch 11 -- lr = 1, duration = 31.8 ms
2017-07-31 02:11:38,638 _log_update: [1206] (50.9 %) of epoch 11 -- lr = 1, duration = 31.9 ms
2017-07-31 02:12:42,528 _log_update: [1406] (59.3 %) of epoch 11 -- lr = 1, duration = 32.0 ms
2017-07-31 02:13:46,414 _log_update: [1606] (67.7 %) of epoch 11 -- lr = 1, duration = 31.9 ms
2017-07-31 02:14:50,301 _log_update: [1806] (76.2 %) of epoch 11 -- lr = 1, duration = 32.1 ms
2017-07-31 02:15:54,183 _log_update: [2006] (84.6 %) of epoch 11 -- lr = 1, duration = 32.0 ms
2017-07-31 02:16:58,059 _log_update: [2206] (93.0 %) of epoch 11 -- lr = 1, duration = 31.7 ms
2017-07-31 02:17:52,719 _validate: [2365] First validation sample, perplexity 164.49.
2017-07-31 02:18:05,202 _validate: [2368] Center of validation, perplexity 163.57.
2017-07-31 02:18:17,710 _validate: [2371] Last validation sample, perplexity 163.44.
2017-07-31 02:18:17,725 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-31 02:18:17,725 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 164.7 [163.6]
2017-07-31 02:18:17,726 _reset: Generating a random order of input lines.
Finished training epoch 11 in 0 hours 13.1 minutes. Best validation perplexity 163.57.
2017-07-31 02:18:28,894 _log_update: [35] (1.5 %) of epoch 12 -- lr = 1, duration = 32.0 ms
2017-07-31 02:19:32,800 _log_update: [235] (9.9 %) of epoch 12 -- lr = 1, duration = 31.9 ms
2017-07-31 02:20:36,685 _log_update: [435] (18.3 %) of epoch 12 -- lr = 1, duration = 31.7 ms
2017-07-31 02:21:40,573 _log_update: [635] (26.8 %) of epoch 12 -- lr = 1, duration = 31.7 ms
2017-07-31 02:22:44,461 _log_update: [835] (35.2 %) of epoch 12 -- lr = 1, duration = 31.8 ms
2017-07-31 02:23:48,330 _log_update: [1035] (43.7 %) of epoch 12 -- lr = 1, duration = 31.8 ms
2017-07-31 02:24:52,232 _log_update: [1235] (52.1 %) of epoch 12 -- lr = 1, duration = 32.0 ms
2017-07-31 02:25:56,130 _log_update: [1435] (60.5 %) of epoch 12 -- lr = 1, duration = 32.3 ms
2017-07-31 02:27:00,085 _log_update: [1635] (69.0 %) of epoch 12 -- lr = 1, duration = 31.9 ms
2017-07-31 02:28:04,003 _log_update: [1835] (77.4 %) of epoch 12 -- lr = 1, duration = 31.9 ms
2017-07-31 02:29:07,910 _log_update: [2035] (85.8 %) of epoch 12 -- lr = 1, duration = 31.8 ms
2017-07-31 02:30:11,841 _log_update: [2235] (94.3 %) of epoch 12 -- lr = 1, duration = 31.9 ms
2017-07-31 02:30:57,212 _validate: [2365] First validation sample, perplexity 164.25.
2017-07-31 02:31:09,695 _validate: [2368] Center of validation, perplexity 163.69.
2017-07-31 02:31:22,193 _validate: [2371] Last validation sample, perplexity 164.15.
2017-07-31 02:31:22,194 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 164.7 [163.6] 164.0
2017-07-31 02:31:22,195 set_state: layers/projection_layer/W <- array(10001, 100)
2017-07-31 02:31:22,196 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-07-31 02:31:22,196 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-07-31 02:31:22,197 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-07-31 02:31:22,200 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-07-31 02:31:22,200 set_state: layers/output_layer/input/b <- array(10001,)
2017-07-31 02:31:22,201 _reset_state: [2368] (99.87 %) of epoch 11
2017-07-31 02:31:22,202 _log_validation: [2368] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 164.7 [163.6]
2017-07-31 02:31:22,202 set_state: Restored iterator to line 42022 of 42068.
2017-07-31 02:31:22,202 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-07-31 02:31:22,210 set_state: layers/output_layer/input/W_gradient <- array(256, 10001)
2017-07-31 02:31:22,211 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2017-07-31 02:31:22,212 set_state: layers/output_layer/input/b_gradient <- array(10001,)
2017-07-31 02:31:22,212 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-07-31 02:31:22,213 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
Model performance stopped improving. Decreasing learning rate from 1.25 to 0.625 and resetting state to 100 % of epoch 11.
2017-07-31 02:31:22,214 _reset: Generating a random order of input lines.
Finished training epoch 11 in 0 hours 13.1 minutes. Best validation perplexity 163.57.
2017-07-31 02:31:42,639 _log_update: [64] (2.7 %) of epoch 12 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:32:46,534 _log_update: [264] (11.1 %) of epoch 12 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:33:50,408 _log_update: [464] (19.6 %) of epoch 12 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:34:54,301 _log_update: [664] (28.0 %) of epoch 12 -- lr = 0.6, duration = 32.0 ms
2017-07-31 02:35:58,184 _log_update: [864] (36.4 %) of epoch 12 -- lr = 0.6, duration = 32.0 ms
2017-07-31 02:37:02,120 _log_update: [1064] (44.9 %) of epoch 12 -- lr = 0.6, duration = 31.8 ms
2017-07-31 02:38:06,067 _log_update: [1264] (53.3 %) of epoch 12 -- lr = 0.6, duration = 32.1 ms
2017-07-31 02:39:09,976 _log_update: [1464] (61.7 %) of epoch 12 -- lr = 0.6, duration = 31.7 ms
2017-07-31 02:40:13,839 _log_update: [1664] (70.2 %) of epoch 12 -- lr = 0.6, duration = 31.7 ms
2017-07-31 02:41:17,702 _log_update: [1864] (78.6 %) of epoch 12 -- lr = 0.6, duration = 32.0 ms
2017-07-31 02:42:21,603 _log_update: [2064] (87.1 %) of epoch 12 -- lr = 0.6, duration = 31.7 ms
2017-07-31 02:43:25,465 _log_update: [2264] (95.5 %) of epoch 12 -- lr = 0.6, duration = 31.8 ms
2017-07-31 02:44:01,580 _validate: [2365] First validation sample, perplexity 163.43.
2017-07-31 02:44:14,067 _validate: [2368] Center of validation, perplexity 163.30.
2017-07-31 02:44:26,562 _validate: [2371] Last validation sample, perplexity 163.58.
2017-07-31 02:44:26,578 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-31 02:44:26,578 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 164.7 163.6 [163.4]
2017-07-31 02:44:26,579 _reset: Generating a random order of input lines.
Finished training epoch 12 in 0 hours 13.1 minutes. Best validation perplexity 163.37.
2017-07-31 02:44:56,263 _log_update: [93] (3.9 %) of epoch 13 -- lr = 0.6, duration = 31.7 ms
2017-07-31 02:46:00,164 _log_update: [293] (12.4 %) of epoch 13 -- lr = 0.6, duration = 32.5 ms
2017-07-31 02:47:03,996 _log_update: [493] (20.8 %) of epoch 13 -- lr = 0.6, duration = 32.0 ms
2017-07-31 02:48:07,909 _log_update: [693] (29.2 %) of epoch 13 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:49:11,792 _log_update: [893] (37.7 %) of epoch 13 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:50:15,703 _log_update: [1093] (46.1 %) of epoch 13 -- lr = 0.6, duration = 32.1 ms
2017-07-31 02:51:19,567 _log_update: [1293] (54.5 %) of epoch 13 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:52:23,470 _log_update: [1493] (63.0 %) of epoch 13 -- lr = 0.6, duration = 31.8 ms
2017-07-31 02:53:27,385 _log_update: [1693] (71.4 %) of epoch 13 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:54:31,298 _log_update: [1893] (79.8 %) of epoch 13 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:55:35,225 _log_update: [2093] (88.3 %) of epoch 13 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:56:39,111 _log_update: [2293] (96.7 %) of epoch 13 -- lr = 0.6, duration = 31.9 ms
2017-07-31 02:57:05,972 _validate: [2365] First validation sample, perplexity 162.55.
2017-07-31 02:57:18,455 _validate: [2368] Center of validation, perplexity 162.55.
2017-07-31 02:57:30,976 _validate: [2371] Last validation sample, perplexity 162.49.
2017-07-31 02:57:30,992 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-07-31 02:57:30,992 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 164.7 163.6 163.4 [162.6]
2017-07-31 02:57:30,993 _reset: Generating a random order of input lines.
Finished training epoch 13 in 0 hours 13.1 minutes. Best validation perplexity 162.55.
2017-07-31 02:58:09,935 _log_update: [122] (5.1 %) of epoch 14 -- lr = 0.6, duration = 32.0 ms
2017-07-31 02:59:13,776 _log_update: [322] (13.6 %) of epoch 14 -- lr = 0.6, duration = 31.8 ms
2017-07-31 03:00:17,639 _log_update: [522] (22.0 %) of epoch 14 -- lr = 0.6, duration = 31.9 ms
2017-07-31 03:01:21,473 _log_update: [722] (30.5 %) of epoch 14 -- lr = 0.6, duration = 31.8 ms
2017-07-31 03:02:25,394 _log_update: [922] (38.9 %) of epoch 14 -- lr = 0.6, duration = 31.9 ms
2017-07-31 03:03:29,266 _log_update: [1122] (47.3 %) of epoch 14 -- lr = 0.6, duration = 31.9 ms
2017-07-31 03:04:33,126 _log_update: [1322] (55.8 %) of epoch 14 -- lr = 0.6, duration = 31.6 ms
2017-07-31 03:05:37,052 _log_update: [1522] (64.2 %) of epoch 14 -- lr = 0.6, duration = 31.9 ms
2017-07-31 03:06:40,954 _log_update: [1722] (72.6 %) of epoch 14 -- lr = 0.6, duration = 31.9 ms
2017-07-31 03:07:44,836 _log_update: [1922] (81.1 %) of epoch 14 -- lr = 0.6, duration = 31.9 ms
2017-07-31 03:08:48,738 _log_update: [2122] (89.5 %) of epoch 14 -- lr = 0.6, duration = 31.8 ms
2017-07-31 03:09:52,612 _log_update: [2322] (97.9 %) of epoch 14 -- lr = 0.6, duration = 31.9 ms
2017-07-31 03:10:10,202 _validate: [2365] First validation sample, perplexity 163.53.
2017-07-31 03:10:22,677 _validate: [2368] Center of validation, perplexity 163.47.
2017-07-31 03:10:35,182 _validate: [2371] Last validation sample, perplexity 163.48.
2017-07-31 03:10:35,183 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 164.7 163.6 163.4 [162.6] 163.6
2017-07-31 03:10:35,184 set_state: layers/projection_layer/W <- array(10001, 100)
2017-07-31 03:10:35,185 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-07-31 03:10:35,185 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-07-31 03:10:35,185 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-07-31 03:10:35,188 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-07-31 03:10:35,189 set_state: layers/output_layer/input/b <- array(10001,)
2017-07-31 03:10:35,190 _reset_state: [2368] (99.87 %) of epoch 13
2017-07-31 03:10:35,190 _log_validation: [2368] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 164.7 163.6 163.4 [162.6]
2017-07-31 03:10:35,191 set_state: Restored iterator to line 42022 of 42068.
2017-07-31 03:10:35,191 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-07-31 03:10:35,199 set_state: layers/output_layer/input/W_gradient <- array(256, 10001)
2017-07-31 03:10:35,200 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2017-07-31 03:10:35,201 set_state: layers/output_layer/input/b_gradient <- array(10001,)
2017-07-31 03:10:35,201 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-07-31 03:10:35,202 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
Model performance stopped improving. Decreasing learning rate from 0.625 to 0.3125 and resetting state to 100 % of epoch 13.
2017-07-31 03:10:35,202 _reset: Generating a random order of input lines.
Finished training epoch 13 in 0 hours 13.1 minutes. Best validation perplexity 162.55.
2017-07-31 03:11:23,401 _log_update: [151] (6.4 %) of epoch 14 -- lr = 0.3, duration = 31.8 ms
2017-07-31 03:12:27,306 _log_update: [351] (14.8 %) of epoch 14 -- lr = 0.3, duration = 32.1 ms
2017-07-31 03:13:31,199 _log_update: [551] (23.2 %) of epoch 14 -- lr = 0.3, duration = 31.8 ms
2017-07-31 03:14:35,124 _log_update: [751] (31.7 %) of epoch 14 -- lr = 0.3, duration = 31.9 ms
2017-07-31 03:15:38,974 _log_update: [951] (40.1 %) of epoch 14 -- lr = 0.3, duration = 31.8 ms
2017-07-31 03:16:42,839 _log_update: [1151] (48.5 %) of epoch 14 -- lr = 0.3, duration = 31.8 ms
2017-07-31 03:17:46,675 _log_update: [1351] (57.0 %) of epoch 14 -- lr = 0.3, duration = 31.9 ms
2017-07-31 03:18:50,566 _log_update: [1551] (65.4 %) of epoch 14 -- lr = 0.3, duration = 32.1 ms
2017-07-31 03:19:54,428 _log_update: [1751] (73.9 %) of epoch 14 -- lr = 0.3, duration = 31.7 ms
2017-07-31 03:20:58,335 _log_update: [1951] (82.3 %) of epoch 14 -- lr = 0.3, duration = 31.9 ms
2017-07-31 03:22:02,231 _log_update: [2151] (90.7 %) of epoch 14 -- lr = 0.3, duration = 31.8 ms
2017-07-31 03:23:06,112 _log_update: [2351] (99.2 %) of epoch 14 -- lr = 0.3, duration = 31.6 ms
2017-07-31 03:23:14,444 _validate: [2365] First validation sample, perplexity 163.50.
2017-07-31 03:23:26,925 _validate: [2368] Center of validation, perplexity 163.35.
2017-07-31 03:23:39,437 _validate: [2371] Last validation sample, perplexity 163.37.
2017-07-31 03:23:39,438 _log_validation: [2371] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 164.7 163.6 163.4 [162.6] 163.4
2017-07-31 03:23:39,439 set_state: layers/projection_layer/W <- array(10001, 100)
2017-07-31 03:23:39,440 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-07-31 03:23:39,440 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-07-31 03:23:39,441 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-07-31 03:23:39,444 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-07-31 03:23:39,444 set_state: layers/output_layer/input/b <- array(10001,)
2017-07-31 03:23:39,445 _reset_state: [2368] (99.87 %) of epoch 13
2017-07-31 03:23:39,446 _log_validation: [2368] Validation set cost history: 357.5 254.7 231.3 207.8 193.5 177.3 168.2 167.3 165.5 164.7 163.6 163.4 [162.6]
2017-07-31 03:23:39,446 set_state: Restored iterator to line 42022 of 42068.
2017-07-31 03:23:39,446 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-07-31 03:23:39,454 set_state: layers/output_layer/input/W_gradient <- array(256, 10001)
2017-07-31 03:23:39,455 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2017-07-31 03:23:39,456 set_state: layers/output_layer/input/b_gradient <- array(10001,)
2017-07-31 03:23:39,457 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-07-31 03:23:39,457 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
Model performance stopped improving. Decreasing learning rate from 0.3125 to 0.15625 and resetting state to 100 % of epoch 13.
Finished training epoch 13 in 0 hours 13.1 minutes. Best validation perplexity 162.55.
Training finished in 4 hours 21.5 minutes.
2017-07-31 03:23:39,460 set_state: layers/projection_layer/W <- array(10001, 100)
2017-07-31 03:23:39,460 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-07-31 03:23:39,461 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-07-31 03:23:39,461 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-07-31 03:23:39,465 set_state: layers/output_layer/input/W <- array(256, 10001)
2017-07-31 03:23:39,465 set_state: layers/output_layer/input/b <- array(10001,)
Best validation set perplexity: 162.5483106
train finished.
Computing evaluation set perplexity.
Reading vocabulary from network state.
Number of words in vocabulary: 10001
Number of words in shortlist: 10001
Number of word classes: 10001
Building neural network.
Restoring neural network state.
Building text scorer.
Number of sentences: 3761
Number of words: 86191
Number of tokens: 86191
Number of predicted probabilities: 82430
Number of excluded (OOV) words: 0
Number of zero probabilities: 0
Cross entropy (base e): 4.896468968991843
Perplexity: 133.8164344988668
