THEANO_FLAGS=floatX=float32,device=cuda0,nvcc.fastmath=True
Reading vocabulary from /l/senarvi/git/theanolm/recipes/penn-treebank/shortlist.txt.
Computing unigram probabilities for out-of-shortlist words.
Number of words in vocabulary: 10001
Number of words in shortlist: 1003
Number of word classes: 1003
2017-05-20 23:57:29,730 train: TRAINING OPTIONS
2017-05-20 23:57:29,730 train: max_epochs: 15
2017-05-20 23:57:29,730 train: patience: 0
2017-05-20 23:57:29,730 train: stopping_criterion: no-improvement
2017-05-20 23:57:29,730 train: validation_frequency: 1
2017-05-20 23:57:29,730 train: batch_size: 32
2017-05-20 23:57:29,730 train: sequence_length: 25
2017-05-20 23:57:29,731 train: max_annealing_count: 0
2017-05-20 23:57:29,731 train: min_epochs: 1
2017-05-20 23:57:29,731 train: OPTIMIZATION OPTIONS
2017-05-20 23:57:29,731 train: ignore_unk: False
2017-05-20 23:57:29,731 train: gradient_decay_rate: 0.9
2017-05-20 23:57:29,731 train: epsilon: 1e-06
2017-05-20 23:57:29,731 train: momentum: 0.9
2017-05-20 23:57:29,731 train: weights: [ 1.]
2017-05-20 23:57:29,731 train: method: adagrad
2017-05-20 23:57:29,731 train: num_noise_samples: 1
2017-05-20 23:57:29,731 train: max_gradient_norm: 5.0
2017-05-20 23:57:29,731 train: noise_sharing: None
2017-05-20 23:57:29,731 train: sqr_gradient_decay_rate: 0.999
2017-05-20 23:57:29,731 train: unk_penalty: None
2017-05-20 23:57:29,731 train: cost_function: cross-entropy
2017-05-20 23:57:29,732 train: learning_rate: 1.0
Creating trainer.
Computing class unigram probabilities and the number of mini-batches in training data.
2017-05-20 23:57:31,321 __init__: One epoch of training data contains 1778 mini-batch updates.
2017-05-20 23:57:31,321 __init__: Class unigram probabilities are in the range [0.00011235, 0.24554914].
2017-05-20 23:57:31,322 __init__: Finding sentence start positions in /teamwork/t40511_asr/c/penn-treebank-project/ptb.train.txt.
2017-05-20 23:57:31,371 _reset: Generating a random order of input lines.
Building neural network.
2017-05-20 23:57:31,383 __init__: Creating layers.
2017-05-20 23:57:31,384 __init__: - NetworkInput name=word_input inputs=[] size=1003 depth=1 devices=[]
2017-05-20 23:57:31,384 __init__: - ProjectionLayer name=projection_layer inputs=[word_input] size=100 depth=1 devices=[None]
2017-05-20 23:57:31,392 add:      * layers/projection_layer/W size=100300 type=float32 device=None
2017-05-20 23:57:31,392 __init__: - LSTMLayer name=hidden_layer inputs=[projection_layer] size=256 depth=1 devices=[None]
2017-05-20 23:57:31,400 add:      * layers/hidden_layer/layer_input/W size=102400 type=float32 device=None
2017-05-20 23:57:31,673 add:      * layers/hidden_layer/step_input/W size=262144 type=float32 device=None
2017-05-20 23:57:31,674 add:      * layers/hidden_layer/layer_input/b size=1024 type=float32 device=None
2017-05-20 23:57:31,674 __init__: - SoftmaxLayer name=output_layer inputs=[hidden_layer] size=1003 depth=1 devices=[None]
2017-05-20 23:57:31,701 add:      * layers/output_layer/input/W size=256768 type=float32 device=None
2017-05-20 23:57:31,701 add:      * layers/output_layer/input/b size=1003 type=float32 device=None
2017-05-20 23:57:31,701 __init__: Total number of parameters: 723639
Compiling optimization function.
2017-05-20 23:57:33,350 add:      * layers/output_layer/input/W_gradient size=256768 type=float32 device=None
2017-05-20 23:57:33,351 add:      * layers/output_layer/input/W_sum_sqr_gradient size=256768 type=float32 device=None
2017-05-20 23:57:33,351 add:      * layers/output_layer/input/b_gradient size=1003 type=float32 device=None
2017-05-20 23:57:33,351 add:      * layers/output_layer/input/b_sum_sqr_gradient size=1003 type=float32 device=None
2017-05-20 23:57:33,352 add:      * layers/projection_layer/W_gradient size=100300 type=float32 device=None
2017-05-20 23:57:33,352 add:      * layers/projection_layer/W_sum_sqr_gradient size=100300 type=float32 device=None
2017-05-20 23:57:33,352 add:      * layers/hidden_layer/layer_input/b_gradient size=1024 type=float32 device=None
2017-05-20 23:57:33,352 add:      * layers/hidden_layer/layer_input/b_sum_sqr_gradient size=1024 type=float32 device=None
2017-05-20 23:57:33,353 add:      * layers/hidden_layer/layer_input/W_gradient size=102400 type=float32 device=None
2017-05-20 23:57:33,353 add:      * layers/hidden_layer/layer_input/W_sum_sqr_gradient size=102400 type=float32 device=None
2017-05-20 23:57:33,354 add:      * layers/hidden_layer/step_input/W_gradient size=262144 type=float32 device=None
2017-05-20 23:57:33,354 add:      * layers/hidden_layer/step_input/W_sum_sqr_gradient size=262144 type=float32 device=None
Building text scorer for cross-validation.
Validation text: /teamwork/t40511_asr/c/penn-treebank-project/ptb.valid.txt
Training neural network.
2017-05-20 23:58:25,304 _log_update: [200] (11.2 %) of epoch 1 -- lr = 1, duration = 3.4 ms
2017-05-20 23:58:32,347 _log_update: [400] (22.5 %) of epoch 1 -- lr = 1, duration = 3.4 ms
2017-05-20 23:58:39,394 _log_update: [600] (33.7 %) of epoch 1 -- lr = 1, duration = 3.4 ms
2017-05-20 23:58:46,434 _log_update: [800] (45.0 %) of epoch 1 -- lr = 1, duration = 3.4 ms
2017-05-20 23:58:53,478 _log_update: [1000] (56.2 %) of epoch 1 -- lr = 1, duration = 3.4 ms
2017-05-20 23:59:00,528 _log_update: [1200] (67.5 %) of epoch 1 -- lr = 1, duration = 3.4 ms
2017-05-20 23:59:07,569 _log_update: [1400] (78.7 %) of epoch 1 -- lr = 1, duration = 3.4 ms
2017-05-20 23:59:14,614 _log_update: [1600] (90.0 %) of epoch 1 -- lr = 1, duration = 3.4 ms
2017-05-20 23:59:22,011 _validate: [1772] First validation sample, perplexity 230.58.
2017-05-20 23:59:26,117 _validate: [1775] Center of validation, perplexity 230.40.
2017-05-20 23:59:30,308 _validate: [1778] Last validation sample, perplexity 230.25.
2017-05-20 23:59:30,318 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-05-20 23:59:30,318 _log_validation: [1778] Validation set cost history: [230.6]
2017-05-20 23:59:30,319 _reset: Generating a random order of input lines.
Finished training epoch 1 in 0 hours 1.2 minutes. Best validation perplexity 230.58.
2017-05-20 23:59:31,068 _log_update: [22] (1.2 %) of epoch 2 -- lr = 1, duration = 3.3 ms
2017-05-20 23:59:37,853 _log_update: [222] (12.5 %) of epoch 2 -- lr = 1, duration = 3.3 ms
2017-05-20 23:59:44,636 _log_update: [422] (23.7 %) of epoch 2 -- lr = 1, duration = 3.3 ms
2017-05-20 23:59:51,431 _log_update: [622] (35.0 %) of epoch 2 -- lr = 1, duration = 3.3 ms
2017-05-20 23:59:58,212 _log_update: [822] (46.2 %) of epoch 2 -- lr = 1, duration = 3.3 ms
2017-05-21 00:00:05,007 _log_update: [1022] (57.5 %) of epoch 2 -- lr = 1, duration = 3.3 ms
2017-05-21 00:00:11,817 _log_update: [1222] (68.7 %) of epoch 2 -- lr = 1, duration = 3.3 ms
2017-05-21 00:00:18,596 _log_update: [1422] (80.0 %) of epoch 2 -- lr = 1, duration = 3.3 ms
2017-05-21 00:00:25,400 _log_update: [1622] (91.2 %) of epoch 2 -- lr = 1, duration = 3.3 ms
2017-05-21 00:00:31,823 _validate: [1772] First validation sample, perplexity 215.54.
2017-05-21 00:00:35,909 _validate: [1775] Center of validation, perplexity 215.44.
2017-05-21 00:00:40,007 _validate: [1778] Last validation sample, perplexity 215.12.
2017-05-21 00:00:40,013 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-05-21 00:00:40,013 _log_validation: [1778] Validation set cost history: 230.6 [215.4]
2017-05-21 00:00:40,014 _reset: Generating a random order of input lines.
Finished training epoch 2 in 0 hours 1.2 minutes. Best validation perplexity 215.44.
2017-05-21 00:00:41,514 _log_update: [44] (2.5 %) of epoch 3 -- lr = 1, duration = 3.3 ms
2017-05-21 00:00:48,320 _log_update: [244] (13.7 %) of epoch 3 -- lr = 1, duration = 3.3 ms
2017-05-21 00:00:55,129 _log_update: [444] (25.0 %) of epoch 3 -- lr = 1, duration = 3.3 ms
2017-05-21 00:01:01,943 _log_update: [644] (36.2 %) of epoch 3 -- lr = 1, duration = 3.3 ms
2017-05-21 00:01:08,748 _log_update: [844] (47.5 %) of epoch 3 -- lr = 1, duration = 3.3 ms
2017-05-21 00:01:15,609 _log_update: [1044] (58.7 %) of epoch 3 -- lr = 1, duration = 3.3 ms
2017-05-21 00:01:22,458 _log_update: [1244] (70.0 %) of epoch 3 -- lr = 1, duration = 3.3 ms
2017-05-21 00:01:29,269 _log_update: [1444] (81.2 %) of epoch 3 -- lr = 1, duration = 3.3 ms
2017-05-21 00:01:36,086 _log_update: [1644] (92.5 %) of epoch 3 -- lr = 1, duration = 3.3 ms
2017-05-21 00:01:41,778 _validate: [1772] First validation sample, perplexity 211.86.
2017-05-21 00:01:45,885 _validate: [1775] Center of validation, perplexity 211.67.
2017-05-21 00:01:50,073 _validate: [1778] Last validation sample, perplexity 211.84.
2017-05-21 00:01:50,079 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-05-21 00:01:50,079 _log_validation: [1778] Validation set cost history: 230.6 215.4 [211.9]
2017-05-21 00:01:50,080 _reset: Generating a random order of input lines.
Finished training epoch 3 in 0 hours 1.2 minutes. Best validation perplexity 211.86.
2017-05-21 00:01:52,321 _log_update: [66] (3.7 %) of epoch 4 -- lr = 1, duration = 3.3 ms
2017-05-21 00:01:59,182 _log_update: [266] (15.0 %) of epoch 4 -- lr = 1, duration = 3.3 ms
2017-05-21 00:02:06,048 _log_update: [466] (26.2 %) of epoch 4 -- lr = 1, duration = 3.4 ms
2017-05-21 00:02:12,913 _log_update: [666] (37.5 %) of epoch 4 -- lr = 1, duration = 3.3 ms
2017-05-21 00:02:19,713 _log_update: [866] (48.7 %) of epoch 4 -- lr = 1, duration = 3.3 ms
2017-05-21 00:02:26,496 _log_update: [1066] (60.0 %) of epoch 4 -- lr = 1, duration = 3.3 ms
2017-05-21 00:02:33,288 _log_update: [1266] (71.2 %) of epoch 4 -- lr = 1, duration = 3.3 ms
2017-05-21 00:02:40,107 _log_update: [1466] (82.5 %) of epoch 4 -- lr = 1, duration = 3.3 ms
2017-05-21 00:02:46,934 _log_update: [1666] (93.7 %) of epoch 4 -- lr = 1, duration = 3.3 ms
2017-05-21 00:02:51,883 _validate: [1772] First validation sample, perplexity 213.32.
2017-05-21 00:02:55,969 _validate: [1775] Center of validation, perplexity 213.36.
2017-05-21 00:03:00,068 _validate: [1778] Last validation sample, perplexity 213.24.
2017-05-21 00:03:00,068 _log_validation: [1778] Validation set cost history: 230.6 215.4 [211.9] 213.3
2017-05-21 00:03:00,069 set_state: layers/projection_layer/W <- array(1003, 100)
2017-05-21 00:03:00,069 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-05-21 00:03:00,070 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-05-21 00:03:00,070 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-05-21 00:03:00,071 set_state: layers/output_layer/input/b <- array(1003,)
2017-05-21 00:03:00,071 set_state: layers/output_layer/input/W <- array(256, 1003)
2017-05-21 00:03:00,072 _reset_state: [1775] (99.83 %) of epoch 3
2017-05-21 00:03:00,073 _log_validation: [1775] Validation set cost history: 230.6 215.4 [211.9]
2017-05-21 00:03:00,073 set_state: Restored iterator to line 42007 of 42068.
2017-05-21 00:03:00,074 set_state: layers/output_layer/input/b_sum_sqr_gradient <- array(1003,)
2017-05-21 00:03:00,074 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-05-21 00:03:00,074 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
2017-05-21 00:03:00,075 set_state: layers/projection_layer/W_sum_sqr_gradient <- array(1003, 100)
2017-05-21 00:03:00,075 set_state: layers/hidden_layer/layer_input/W_sum_sqr_gradient <- array(100, 1024)
2017-05-21 00:03:00,076 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-05-21 00:03:00,076 set_state: layers/hidden_layer/step_input/W_sum_sqr_gradient <- array(256, 1024)
2017-05-21 00:03:00,077 set_state: layers/output_layer/input/b_gradient <- array(1003,)
2017-05-21 00:03:00,077 set_state: layers/output_layer/input/W_gradient <- array(256, 1003)
2017-05-21 00:03:00,078 set_state: layers/projection_layer/W_gradient <- array(1003, 100)
2017-05-21 00:03:00,078 set_state: layers/hidden_layer/layer_input/b_sum_sqr_gradient <- array(1024,)
2017-05-21 00:03:00,079 set_state: layers/output_layer/input/W_sum_sqr_gradient <- array(256, 1003)
Model performance stopped improving. Decreasing learning rate from 1.0 to 0.5 and resetting state to 100 % of epoch 3.
2017-05-21 00:03:00,080 _reset: Generating a random order of input lines.
Finished training epoch 3 in 0 hours 1.2 minutes. Best validation perplexity 211.86.
2017-05-21 00:03:03,071 _log_update: [88] (4.9 %) of epoch 4 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:03:09,856 _log_update: [288] (16.2 %) of epoch 4 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:03:16,667 _log_update: [488] (27.4 %) of epoch 4 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:03:23,478 _log_update: [688] (38.7 %) of epoch 4 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:03:30,267 _log_update: [888] (49.9 %) of epoch 4 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:03:37,056 _log_update: [1088] (61.2 %) of epoch 4 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:03:43,893 _log_update: [1288] (72.4 %) of epoch 4 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:03:50,726 _log_update: [1488] (83.7 %) of epoch 4 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:03:57,523 _log_update: [1688] (94.9 %) of epoch 4 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:04:01,712 _validate: [1772] First validation sample, perplexity 204.82.
2017-05-21 00:04:05,849 _validate: [1775] Center of validation, perplexity 204.72.
2017-05-21 00:04:09,950 _validate: [1778] Last validation sample, perplexity 204.76.
2017-05-21 00:04:09,956 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2017-05-21 00:04:09,956 _log_validation: [1778] Validation set cost history: 230.6 215.4 211.9 [204.8]
2017-05-21 00:04:09,957 _reset: Generating a random order of input lines.
Finished training epoch 4 in 0 hours 1.2 minutes. Best validation perplexity 204.76.
2017-05-21 00:04:13,692 _log_update: [110] (6.2 %) of epoch 5 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:04:20,482 _log_update: [310] (17.4 %) of epoch 5 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:04:27,298 _log_update: [510] (28.7 %) of epoch 5 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:04:34,095 _log_update: [710] (39.9 %) of epoch 5 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:04:40,881 _log_update: [910] (51.2 %) of epoch 5 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:04:47,670 _log_update: [1110] (62.4 %) of epoch 5 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:04:54,455 _log_update: [1310] (73.7 %) of epoch 5 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:05:01,246 _log_update: [1510] (84.9 %) of epoch 5 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:05:08,033 _log_update: [1710] (96.2 %) of epoch 5 -- lr = 0.5, duration = 3.3 ms
2017-05-21 00:05:11,487 _validate: [1772] First validation sample, perplexity 207.71.
2017-05-21 00:05:15,578 _validate: [1775] Center of validation, perplexity 207.85.
2017-05-21 00:05:19,687 _validate: [1778] Last validation sample, perplexity 207.86.
2017-05-21 00:05:19,687 _log_validation: [1778] Validation set cost history: 230.6 215.4 211.9 [204.8] 207.8
2017-05-21 00:05:19,687 set_state: layers/projection_layer/W <- array(1003, 100)
2017-05-21 00:05:19,688 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-05-21 00:05:19,688 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-05-21 00:05:19,689 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-05-21 00:05:19,689 set_state: layers/output_layer/input/b <- array(1003,)
2017-05-21 00:05:19,690 set_state: layers/output_layer/input/W <- array(256, 1003)
2017-05-21 00:05:19,691 _reset_state: [1775] (99.83 %) of epoch 4
2017-05-21 00:05:19,691 _log_validation: [1775] Validation set cost history: 230.6 215.4 211.9 [204.8]
2017-05-21 00:05:19,692 set_state: Restored iterator to line 42004 of 42068.
2017-05-21 00:05:19,692 set_state: layers/output_layer/input/b_sum_sqr_gradient <- array(1003,)
2017-05-21 00:05:19,693 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-05-21 00:05:19,693 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
2017-05-21 00:05:19,693 set_state: layers/projection_layer/W_sum_sqr_gradient <- array(1003, 100)
2017-05-21 00:05:19,694 set_state: layers/hidden_layer/layer_input/W_sum_sqr_gradient <- array(100, 1024)
2017-05-21 00:05:19,695 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-05-21 00:05:19,695 set_state: layers/hidden_layer/step_input/W_sum_sqr_gradient <- array(256, 1024)
2017-05-21 00:05:19,695 set_state: layers/output_layer/input/b_gradient <- array(1003,)
2017-05-21 00:05:19,696 set_state: layers/output_layer/input/W_gradient <- array(256, 1003)
2017-05-21 00:05:19,696 set_state: layers/projection_layer/W_gradient <- array(1003, 100)
2017-05-21 00:05:19,697 set_state: layers/hidden_layer/layer_input/b_sum_sqr_gradient <- array(1024,)
2017-05-21 00:05:19,697 set_state: layers/output_layer/input/W_sum_sqr_gradient <- array(256, 1003)
Model performance stopped improving. Decreasing learning rate from 0.5 to 0.25 and resetting state to 100 % of epoch 4.
2017-05-21 00:05:19,698 _reset: Generating a random order of input lines.
Finished training epoch 4 in 0 hours 1.2 minutes. Best validation perplexity 204.76.
2017-05-21 00:05:24,183 _log_update: [132] (7.4 %) of epoch 5 -- lr = 0.2, duration = 3.3 ms
2017-05-21 00:05:30,979 _log_update: [332] (18.7 %) of epoch 5 -- lr = 0.2, duration = 3.3 ms
2017-05-21 00:05:37,768 _log_update: [532] (29.9 %) of epoch 5 -- lr = 0.2, duration = 3.3 ms
2017-05-21 00:05:44,577 _log_update: [732] (41.2 %) of epoch 5 -- lr = 0.2, duration = 3.3 ms
2017-05-21 00:05:51,372 _log_update: [932] (52.4 %) of epoch 5 -- lr = 0.2, duration = 3.3 ms
2017-05-21 00:05:58,187 _log_update: [1132] (63.7 %) of epoch 5 -- lr = 0.2, duration = 3.3 ms
2017-05-21 00:06:04,986 _log_update: [1332] (74.9 %) of epoch 5 -- lr = 0.2, duration = 3.3 ms
2017-05-21 00:06:11,775 _log_update: [1532] (86.2 %) of epoch 5 -- lr = 0.2, duration = 3.3 ms
2017-05-21 00:06:18,561 _log_update: [1732] (97.4 %) of epoch 5 -- lr = 0.2, duration = 3.3 ms
2017-05-21 00:06:21,253 _validate: [1772] First validation sample, perplexity 205.76.
2017-05-21 00:06:25,339 _validate: [1775] Center of validation, perplexity 205.87.
2017-05-21 00:06:29,445 _validate: [1778] Last validation sample, perplexity 205.68.
2017-05-21 00:06:29,445 _log_validation: [1778] Validation set cost history: 230.6 215.4 211.9 [204.8] 205.8
2017-05-21 00:06:29,446 set_state: layers/projection_layer/W <- array(1003, 100)
2017-05-21 00:06:29,447 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-05-21 00:06:29,447 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-05-21 00:06:29,448 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-05-21 00:06:29,448 set_state: layers/output_layer/input/b <- array(1003,)
2017-05-21 00:06:29,449 set_state: layers/output_layer/input/W <- array(256, 1003)
2017-05-21 00:06:29,450 _reset_state: [1775] (99.83 %) of epoch 4
2017-05-21 00:06:29,450 _log_validation: [1775] Validation set cost history: 230.6 215.4 211.9 [204.8]
2017-05-21 00:06:29,451 set_state: Restored iterator to line 42004 of 42068.
2017-05-21 00:06:29,451 set_state: layers/output_layer/input/b_sum_sqr_gradient <- array(1003,)
2017-05-21 00:06:29,451 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2017-05-21 00:06:29,452 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
2017-05-21 00:06:29,452 set_state: layers/projection_layer/W_sum_sqr_gradient <- array(1003, 100)
2017-05-21 00:06:29,453 set_state: layers/hidden_layer/layer_input/W_sum_sqr_gradient <- array(100, 1024)
2017-05-21 00:06:29,453 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2017-05-21 00:06:29,454 set_state: layers/hidden_layer/step_input/W_sum_sqr_gradient <- array(256, 1024)
2017-05-21 00:06:29,454 set_state: layers/output_layer/input/b_gradient <- array(1003,)
2017-05-21 00:06:29,455 set_state: layers/output_layer/input/W_gradient <- array(256, 1003)
2017-05-21 00:06:29,455 set_state: layers/projection_layer/W_gradient <- array(1003, 100)
2017-05-21 00:06:29,456 set_state: layers/hidden_layer/layer_input/b_sum_sqr_gradient <- array(1024,)
2017-05-21 00:06:29,456 set_state: layers/output_layer/input/W_sum_sqr_gradient <- array(256, 1003)
Model performance stopped improving. Decreasing learning rate from 0.25 to 0.125 and resetting state to 100 % of epoch 4.
Finished training epoch 4 in 0 hours 1.2 minutes. Best validation perplexity 204.76.
Training finished in 0 hours 8.2 minutes.
2017-05-21 00:06:29,458 set_state: layers/projection_layer/W <- array(1003, 100)
2017-05-21 00:06:29,458 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2017-05-21 00:06:29,459 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2017-05-21 00:06:29,459 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2017-05-21 00:06:29,460 set_state: layers/output_layer/input/b <- array(1003,)
2017-05-21 00:06:29,460 set_state: layers/output_layer/input/W <- array(256, 1003)
Best validation set perplexity: 204.716008713
train finished.
